# ğŸ§¾ Sistema de AnÃ¡lisis de Ventas

Este proyecto simula el flujo profesional de anÃ¡lisis de ventas de una compaÃ±Ã­a que opera en varias ciudades.  
El sistema estÃ¡ diseÃ±ado para trabajar con una base de datos relacional (MySQL) y una aplicaciÃ³n escrita en Python, modelada utilizando los principios de **ProgramaciÃ³n Orientada a Objetos (POO)** y buenas prÃ¡cticas de desarrollo.

---

## ğŸ“ Estructura de Carpetas

```
sales_company/
â”œâ”€â”€ data/                           # Archivos CSV originales
â”œâ”€â”€ notebooks/                      # Jupyter notebook para anÃ¡lisis
â”‚   â””â”€â”€ sales_analysis_demo.ipynb
â”œâ”€â”€ sql/                            # Scripts para crear tablas, cargar datos, creacion de indices, procedimientos almacenados y vistas.
â”‚   â””â”€â”€ create_indexes.sql          # Agrega los Ã­ndices recomendados para performance.
â”‚   â””â”€â”€ create_procedure.sql        # Crea los procedimientos almacenados utilizados en el sistema.
â”‚   â””â”€â”€ create_views.sql            # Crea las vistas necesarias para los informes.
â”‚   â””â”€â”€ load_data.sql               # Carga los datos iniciales desde los archivos CSV.
â”œâ”€â”€ src/
â”‚   â””â”€â”€ core/                       # Configuracion de las variables de entorno y validaciones
â”‚   â””â”€â”€ database/                   # Configuracion de la conexion a la base de datos
â”‚   â””â”€â”€ models/                     # Clases que representan las entidades del negocio
â”‚   â””â”€â”€ services/                   # Servicio centralizado para ejecutar y coordinar reportes estratÃ©gicos de ventas.
â”‚   â””â”€â”€ strategies/                 # Estrategias para el analisis de ventas.
â”‚   â””â”€â”€ utils/                      # Funciones de utilidad, logger
â”œâ”€â”€ test/                           # Pruebas unitarias con pytest
â”œâ”€â”€ .env                            # ConfiguraciÃ³n de conexiÃ³n a base de datos
â”œâ”€â”€ .gitignore                      # Exclusiones de control de versiones
â”œâ”€â”€ requirements.txt                # Dependencias del proyecto
â”œâ”€â”€ README.md                       # DocumentaciÃ³n del sistema
```

---

## ğŸ›  Requisitos TÃ©cnicos

- Python **3.12+**
- MySQL Server **8.0+**
- Paquetes de Python:
  - `pandas`
  - `sqlalchemy`
  - `python-dotenv`
  - `pytest`
  - _(otros que se encuentren en `requirements.txt`)_

---

## CÃ³mo crear el entorno virtual e instalar dependencias

```bash
# Crear entorno virtual
python -m venv venv_sales_company

# Activar entorno virtual
# En Windows:
venv\Scripts\activate
# En GitBash desde windows:
source venv\Scripts\activate
# En Mac/Linux:
source venv/bin/activate

# Instalar dependencias
pip install -r requirements.txt
```

---

## ğŸ” ConfiguraciÃ³n del archivo `.env`

Crear un archivo `.env` en la raÃ­z del proyecto con los siguientes valores:

```env
DB_HOST=localhost
DB_USER=tu_usuario
DB_PASSWORD=tu_contraseÃ±a
DB_NAME=sales_company
DB_PORT=3306
```

---

## ğŸ§© CÃ³mo cargar los datos en MySQL Workbench

1. Abrir MySQL Workbench e iniciar sesiÃ³n.
2. Ejecutar el script SQL `sql/load_data.sql` que:

   - Crea la base de datos `sales_company`.
   - Crea todas las tablas necesarias.
   - Carga los archivos `.csv` desde la carpeta `/data/` usando `LOAD DATA LOCAL INFILE` ( ver script `sql/load_data.sql`).

     ğŸ’¡ AsegÃºrate de que la ruta a los archivos `.csv` sea absoluta y compatible con `LOAD DATA LOCAL INFILE` (por ejemplo, `C:/ruta/proyecto/data/archivo.csv`).

3. Asegurarse de tener habilitada la opciÃ³n `local_infile` tanto en el servidor como en el cliente (ver errores `Error Code: 3948` o `2068` si no estÃ¡ habilitado).

---

# ğŸ§± DiseÃ±o del sistema

## ğŸ” clases y modelos

Cada tabla del sistema tiene una clase Python correspondiente en la carpeta `models/`:

- `Category`, `City`, `Country`, `Customer`, `Employee`, `Product`, `Sale`

Cada clase:

- Usa **encapsulamiento** (`__atributo`)
- Tiene **constructores personalizados**
- Incluye **mÃ©todos Ãºtiles** para el negocio (como `get_full_name`, `get_tenure`, `apply_discount`, etc.)
- Implementa `__repr__` para facilitar debugging

---

## ğŸ§± Patrones de diseÃ±o implementados:

### Patron de diseÃ±o singleton

- Uso del patron de diseÃ±o Singleton en `database/connection.py` para generar una unica conexion a la base de datos, con el fin de centralizar la conexion y no generar nuevas conexiones innecesarias

### ğŸ“Œ Consideraciones sobre la elecciÃ³n de patrones de diseÃ±o para anÃ¡lisis de ventas

Siguiendo la consigna propuesta en el inicio del proyecto

<img src="requerimientos.png" width="700">

Durante la etapa de diseÃ±o se evaluÃ³ la posibilidad de implementar el patrÃ³n Builder, con el objetivo de ofrecer a la direcciÃ³n ejecutiva un conjunto de herramientas flexibles y personalizables para construir consultas ad hoc, agregando filtros, agrupaciones y condiciones segÃºn la necesidad puntual de cada anÃ¡lisis.

Sin embargo, el relevamiento de requerimientos dejÃ³ en claro que la necesidad principal de la direcciÃ³n ejecutiva estÃ¡ enfocada en informes periÃ³dicos (diarios y mensuales) de estructura fija y lÃ³gica estable, orientados a:

- Informes periodicos diarios y mensuales ( en este caso, utilizando horas y minutos como equivalentes, ya que la informacion de fechas de ventas se encuentra en formato de tipo `TIME`)

- Consolidar ventas por sucursal (en este caso, utilizando ciudades como equivalentes de sucursales)

- Detectar patrones de comportamiento de los clientes

- Medir el rendimiento de productos y promociones

Dado que la cantidad de informes es acotada y sus criterios son bien definidos, se optÃ³ por el patrÃ³n Strategy para encapsular y desacoplar cada anÃ¡lisis relevante (por sucursal, por hora, por producto, etc.).

Esto permite:

- Profundizar en la calidad y el detalle de cada informe

- Asegurar una implementaciÃ³n Ã¡gil y mantenible

- Facilitar la extensiÃ³n futura (agregando nuevas estrategias segÃºn la evoluciÃ³n del negocio)

En resumen:
Se priorizÃ³ una arquitectura menos flexible pero mÃ¡s reutilizable y robusta para los anÃ¡lisis requeridos, implementando diferentes estrategias de anÃ¡lisis de ventas que consoliden la informaciÃ³n diaria y mensual ( horas y minutos ), detecten patrones de comportamiento y midan el rendimiento de productos y promociones.

### Patron de diseÃ±o Strategy:

- Uso del patron de diseÃ±o Strategy en `stragies/` para el analisis de ventas:
  - `sales_by_branch_and_hour`: Estrategia de anÃ¡lisis que identifica, para cada sucursal, hora y minuto,
    el producto mÃ¡s vendido y el descuento aplicado.
  - `sales_customer_behavior`: Estrategia de anÃ¡lisis de patrones de comportamiento de los clientes. Permite obtener
    - El total gastado, cantidad de transacciones y desglose de gasto con/sin promociÃ³n para cada cliente.
    - La sucursal donde el cliente gastÃ³ mÃ¡s (ciudad de mayor gasto).
    - El producto mÃ¡s comprado por cada cliente.
  - `sales_product_performance`: Estrategia de anÃ¡lisis de rendimiento de productos por sucursal. Permite identificar el top 5 productos mÃ¡s vendidos, con detalle de unidades vendidas, facturaciÃ³n total y ventas con/sin promociÃ³n.

### Patron de diseÃ±o Facade:

- Uso del patron de diseÃ±o facade en `services/report_service` para el acceso a las diferentes estrategias:
  - Servicio centralizado para ejecutar y coordinar reportes estratÃ©gicos de ventas.
  - Encapsula la lÃ³gica para ejecutar diferentes estrategias de anÃ¡lisis.
  - Permite a la capa de presentaciÃ³n acceder a los distintos anÃ¡lisis de negocio de forma simple y desacoplada.

## ğŸ” Consultas SQL avanzadas y Objetos SQL

### Vistas

- Con el fin de lograr un mayor desacoplamiento, flexibilidad en el acceso y anÃ¡lisis de los datos, y permitir la reutilizacion y combinacion de resultados se decidio crear las siguientes vistas:

  - `sql/create_views.sql` -- vw_top_product_by_branch_hour_minute:

    - Uso de la funcion ventana `ROW_NUMBER()` para obtener la numeracion unica de manera secuencial
      - DescripciÃ³n: Devuelve, para cada sucursal (ciudad), hora y minuto, el producto mÃ¡s vendido (mayor cantidad) y su descuento.
      - Uso: `SELECT \* FROM vw_top_product_by_branch_hour_minute;`

  - `sql/create_views.sql` -- vw_customer_behavior:
    - Uso de la funcion ventana `ROW_NUMBER()` para obtener la numeracion unica de manera secuencial
      - DescripciÃ³n: Resumen ejecutivo del comportamiento de los clientes.
      - Uso: `SELECT * FROM vw_customer_behavior;`

### Procedimientos almacenados

- Se implementÃ³ un procedimiento almacenado (store procedure) `sql/create_procedures.sql` -- sp_top_products_by_branch:
  - Uso de la funcion ventana `DENSE_RANK()` para obtener valores de productos empatados con la numeracion continua sin saltos.
  - Con el fin de centralizar la lÃ³gica de obtenciÃ³n de los productos mÃ¡s vendidos por sucursal, optimizando la ejecuciÃ³n de consultas complejas, facilitando su mantenimiento.
    - DescripciÃ³n: Devuelve, para cada sucursal (ciudad), el top N productos mÃ¡s vendidos, con detalle de unidades vendidas, facturaciÃ³n y ventas con/sin promociÃ³n.
    - ParÃ¡metros: `IN top_n INT` -- _NÃºmero de productos a retornar por sucursal (ranking)_
    - Uso: `CALL sp_top_products_by_branch(3);`

### Indices

- Se implementaron indices que buscaban optimizar las consultas:

  - Acelera JOINs y agrupamientos por cliente en ventas: `CREATE INDEX idx_sales_customerid ON sales(CustomerID);`

  - Acelera JOINs y agrupamientos por producto en ventas: `CREATE INDEX idx_sales_productid ON sales(ProductID);`

  - Acelera bÃºsquedas y agrupaciones por fecha/hora de venta: `CREATE INDEX idx_sales_salesdate ON sales(SalesDate);`

_En este entorno y con la cantidad de datos actual, la creaciÃ³n de Ã­ndices no tuvo impacto visible en los tiempos de ejecuciÃ³n del procedimiento almacenado. vease(`notebooks/sales_analysis_demo.ipynb -> Implementacion de indices`). Esto se debe a que el volumen de datos es moderado y la consulta realiza agregaciones sobre toda la tabla, donde el optimizador de MySQL prefiere un escaneo completo. En escenarios productivos con millones de registros y consultas filtradas, los Ã­ndices aportan mejoras significativas en la performance._

## ğŸ“Š Notebook interactivo

En la carpeta `notebooks/` se incluye el archivo `sales_analysis_demo.ipynb`, que muestra:

- ConexiÃ³n y consulta a la base de datos
- Ejemplo del patrÃ³n Singleton en acciÃ³n
- ConversiÃ³n de resultados a DataFrame con `pandas`
- Implementacion de los patrones `Strategy` y `Facade`
- Creacion de consultas avanzadas utilizando `CTE`, `Funciones de ventana` y `Objetos SQL`
- Implementacion de `Indices`
- EjecuciÃ³n de pruebas con `pytest` desde el entorno de Jupyter

## ğŸ§ª CÃ³mo ejecutar los tests en Python

Los tests estÃ¡n ubicados en la carpeta `test/`.

Para correrlos usar el siguiente comando desde la raiz del proyecto:

```bash
pytest
```

Los tests unitarios validan:

- Que los mÃ©todos como `get_full_name` y `get_price` funcionen correctamente
- Que los setters actualicen atributos privados
- Que las representaciones (`__repr__`) devuelvan los valores esperados
- Que el patron singleton aplicado a la conexion con las base de datos funcione correctamente.

---

## ğŸ’¡ Conclusiones y JustificaciÃ³n tÃ©cnica

- Se utilizÃ³ **MySQL** como base de datos relacional, la cual brinda soporte de carga masiva de datos, y compatibilidad con herramientas del ecosistema.
- La carga de datos se realizÃ³ mediante `LOAD DATA LOCAL INFILE`, priorizando eficiencia en comparaciÃ³n con inserciones fila por fila.
- Las clases en Python estÃ¡n diseÃ±adas bajo **principios de POO** para permitir la reutilizaciÃ³n, validaciÃ³n de datos, y crecimiento futuro del sistema.
- El **patrÃ³n Singleton** aplicado a la conexiÃ³n permite mantener una Ãºnica instancia activa de conexiÃ³n a la base de datos durante la ejecuciÃ³n del sistema.
- El **patrÃ³n Strategy** permite desacoplar y organizar mÃºltiples algoritmos de anÃ¡lisis de ventas, haciendo el sistema flexible, escalable y fÃ¡cilmente extensible ante nuevos requerimientos.
- El **patrÃ³n Facade** centraliza y simplifica el acceso a los diferentes informes analÃ­ticos, permitiendo a la capa de presentaciÃ³n interactuar con los anÃ¡lisis de negocio de forma sencilla y desacoplada.
- Las **vistas SQL** contribuyen a desacoplar y reutilizar la lÃ³gica de consulta, facilitando el anÃ¡lisis y reporte de informaciÃ³n estratÃ©gica.
- El **procedimiento almacenado** centraliza y optimiza la obtenciÃ³n del ranking de productos mÃ¡s vendidos por sucursal, simplificando la lÃ³gica y mejorando la mantenibilidad.
- Aunque **los Ã­ndices** no demostraron mejoras significativas de performance en este entorno de prueba, su incorporaciÃ³n deja al sistema preparado para escalar y soportar grandes volÃºmenes de datos en ambientes productivos.
- `pytest` fue elegido como framework de testing por su simplicidad, velocidad y facilidad de integraciÃ³n con proyectos en Python moderno.

---

âš ï¸ A tener en cuenta
Si bien la forma mÃ¡s adecuada de trabajar con SQLAlchemy es mediante el mapeo ORM de las clases y la carga de datos directamente a travÃ©s del cÃ³digo Python, en este proyecto se optÃ³ por utilizar el script load_data.sql para la carga inicial.
Esta decisiÃ³n se tomÃ³ por motivos prÃ¡cticos y para cumplir con las consignas establecidas, priorizando agilidad en el desarrollo y pruebas.

## ğŸš€ PrÃ³ximos pasos y mejoras

- **IntegraciÃ³n completa del ORM**: Migrar gradualmente la lÃ³gica de consultas y manipulaciÃ³n de datos hacia SQLAlchemy en modo ORM, permitiendo aprovechar validaciones automÃ¡ticas, relaciones entre entidades y mayor seguridad en las operaciones.

- **AutomatizaciÃ³n del pipeline de carga**: Implementar scripts o pipelines automatizados para la ingestiÃ³n y validaciÃ³n de datos, facilitando actualizaciones periÃ³dicas y reducciÃ³n de errores humanos.

- **AmpliaciÃ³n de informes y dashboards**: Incorporar nuevos anÃ¡lisis, reportes y visualizaciones (por ejemplo, integraciÃ³n con herramientas de BI como Power BI o Tableau).

- **Control de acceso y autenticaciÃ³n**: AÃ±adir mecanismos de autenticaciÃ³n de usuarios y perfiles de acceso a los distintos informes y funcionalidades del sistema.

- **OptimizaciÃ³n y monitoreo de performance**: Continuar evaluando el impacto de Ã­ndices y planes de ejecuciÃ³n, e incorporar monitoreo automatizado para identificar cuellos de botella ante el crecimiento de datos.
